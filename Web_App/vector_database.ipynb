{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6k7qxVxICIR",
    "outputId": "d1b2eb39-0c22-4c2a-9714-bc36e7825ac3"
   },
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install chromadb\n",
    "# !pip install transformers\n",
    "# !pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E3bQbAqWAQdG"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import VectorDBQA\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "isd67PVfINSS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loader = TextLoader('../RadarPlainText/Radar Basics1.txt')\n",
    "loader = DirectoryLoader('../ThreatInfo/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "documents = loader.load()\n",
    "display(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yyRo3GE9MBkj"
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfiI2bdpMaSH",
    "outputId": "70cfb82b-7fad-478e-87fc-9148012dd1db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings not found on disk. Downloading from Hugging Face...\n",
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save embedding to disk and load if available\n",
    "import torch\n",
    "import os\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "# Downloading from HF took forever, check if embedding is on disk and use that\n",
    "if os.path.exists(\"instructor-xl.pt\"):\n",
    "    # Load embedding from disk\n",
    "    embedding = torch.load(\"instructor-xl.pt\")\n",
    "    print(\"Loaded embeddings from disk.\")\n",
    "else:\n",
    "    # If the embeddings are not found on disk, download them from Hugging Face\n",
    "    print(\"Embeddings not found on disk. Downloading from Hugging Face...\")\n",
    "    embedding = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\", model_kwargs={\"device\": \"cuda\"})\n",
    "    # Save to disk\n",
    "#     torch.save(embedding,\"instructor-xl.pt\")\n",
    "#     print(\"Saved embeddings to disk.\")\n",
    "    \n",
    "    \n",
    "#embedding = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\", \n",
    "#                                                       model_kwargs={\"device\": \"cuda\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2uECDMDoDpUN",
    "outputId": "a454dbbc-ee4a-4756-a061-fcf17594131c"
   },
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(texts, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever\n",
    "#retriever = vectordb.as_retriever()\n",
    "# Return the top k documents\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 8})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test retriever\n",
    "# docs = retriever.get_relevant_documents(\"What is a radar waveform?\")\n",
    "# display(len(docs))\n",
    "# display(docs[0])\n",
    "# display(docs[2])\n",
    "# display(retriever.search_type)\n",
    "# display(retriever.search_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meta-llama/Llama-2-13b-chat-hf'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use Opal Server\n",
    "\n",
    "from _OpalLLM import OpalLLM\n",
    "\n",
    "if 1:\n",
    "    #model_name=\"lmsys/vicuna-33b\"\n",
    "    #model_name=\"databricks/dolly-v2-12b\"\n",
    "    model_name=\"meta-llama/Llama-2-13b-chat-hf\"\n",
    "#     model_name = \"tiiuae/falcon-40b-instruct\"\n",
    "    #model_name=\"CarperAI/stable-vicuna-13b-delta\"\n",
    "    \n",
    "    local_llm=OpalLLM(model=model_name,\n",
    "                      temperature=0.5,\n",
    "                      top_k=60,\n",
    "                      top_p=0.95,\n",
    "                      max_tokens=200,\n",
    "                      repetition_penalty=1.15)\n",
    "    display(local_llm.model)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RetrievalQA Chain\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=local_llm,\n",
    "                                chain_type=\"stuff\",\n",
    "                                retriever=retriever,\n",
    "                                return_source_documents=True,\n",
    "                                verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format this text\n",
    "import textwrap\n",
    "\n",
    "def trim_string(input_string):\n",
    "    input_string = str(input_string)\n",
    "    trim_index = input_string.find(\"### Human:\")\n",
    "    if trim_index != -1:  # If the phrase is found\n",
    "        return input_string[:trim_index]\n",
    "    else:\n",
    "        return input_string  # If the phrase isn't found, return the original string\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    temp_resp = wrap_text_preserve_newlines(llm_response['result'])\n",
    "    temp_resp = trim_string(temp_resp)\n",
    "    if \"</s>\" in temp_resp:\n",
    "        ind = temp_resp.find(\"</s>\")\n",
    "        temp_resp = temp_resp[:ind]\n",
    "    print(temp_resp)\n",
    "    print('\\n\\nSources:')\n",
    "    clean_source_ls = []\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        if source.metadata['source'] not in clean_source_ls:\n",
    "            clean_source_ls.append(source.metadata['source'])\n",
    "    for sources in clean_source_ls:\n",
    "        print(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Based on the text provided, here are some key threats from China that you may want to be aware of as a radar\n",
      "specialist:\n",
      "\n",
      "* China has launched the most satellites of any nation last year, indicating their intent to project hard and\n",
      "soft power through on-orbit military support capabilities.\n",
      "* China has demonstrated counterspace demonstrations such as hypersonic missile launches and co-orbital\n",
      "rendezvous with other satellites.\n",
      "* China has a growing suite of jamming and spoofing electronic warfare capabilities to be used against space\n",
      "and non-space signals alike.\n",
      "* Little is known about China's cyber counterspace capabilities, but their cyber capabilities in other domains\n",
      "suggest a strong foundation for potential cyber counterspace capabilities.\n",
      "\n",
      "\n",
      "Sources:\n",
      "../ThreatInfo/220404_Harrison_SpaceThreatAssessment2022.txt\n"
     ]
    }
   ],
   "source": [
    "# Formatted Test\n",
    "# query = \"What is Range Doppler Processing used for? Give examples of the applications and explain how doppler is used from a physics perspective\"\n",
    "query = \"Summarize and list the main threats from China that I should know about as a radar specialist.\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "gpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
